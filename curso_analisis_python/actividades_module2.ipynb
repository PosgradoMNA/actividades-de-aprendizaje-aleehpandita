{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tec03/ParaAssignment01-/blob/main/assignment01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-Processing Data in Python\n",
        "\n",
        "#### Data Pre-processing\n",
        "-   It is the process of converting or mapping data from one “raw” form into another format to make it ready for further analysis.\n",
        "-   Data cleaning\n",
        "-   Data wrangling\n",
        "\n",
        "*   Identify and handle missing values\n",
        "*   Data Formatting\n",
        "*   Data Normalization (centering / scaling ) (Normalization is a way to bring all data into a similar range, for more useful comparison)\n",
        "*   Data binning\n",
        "*   Turning categorical values to numerics values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dealing with missing values in Python\n",
        "\n",
        "#### What to do when you have missing values in your data?\n",
        "\n",
        "*   Missing values: when no data value is stored for a variable(feature) in an observation\n",
        "*   Could be represented as ?, N/A, 0 or just a blank cell \n",
        "\n",
        "#### How to deal with missing data?\n",
        "\n",
        "*   Each situation is diff and should be judged diff\n",
        "*   The first is to check if the person or group that collected the data can go back and find what the actual value should be\n",
        "*   If you don’t have a lot of observations with missing data, usually dropping the particular entry is the best\n",
        "*   If you’re removing data, you want to look to do something that has the least amountof impact\n",
        "*   Replace missing values is better, no data is wasted\n",
        "*   A replacement technique is to replace missing values by the average value of the entire variable but what if the values cannot be averaged, as with categorical variables?: we can use the most common\n",
        "*   Replace it by frequency\n",
        "*   Replace it based on other functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To remove data that contains missing values, pandas library has a built-in method called ‘dropna’, you can choose to drop rows or columns that contain missing values, like NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframes.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So you’ll need to specify “axis=0” to drop the rows, or “axis=1” to drop the columns that contain the missing values\n",
        "Setting the argument “inplace” to “true” allows the modification to be done on the dataset directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dropna(subset=[\"price\"], axis=0)\n",
        "##this line of code does not change the dataframe, but is a good way to make sure that you are performing the correct operation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To modify the dataframe, you have to set the parameter \"inplace\" equal to true."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.replace(missing_value,new_value)\n",
        "##To replace missing values like NaNs with actual values, pandas library has a built in method called ‘replace’, which can be used to fill in the missing values with the newly calculated values\n",
        "\n",
        "mean = df[\"normalized-losses\"].mean()\n",
        "df[\"normalized-losses\"].replace(np.nan,mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Formatting in Python\n",
        "\n",
        "-   Data is usually collected from different places, by different people, which may be stored in different formats.\n",
        "-   Data formatting means bringing data into a common standard of expression that allows users to make meaningful comparisons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Incorrect data types\n",
        "\n",
        "*   Sometimes the wrong data type is assigned to a feature\n",
        "*   It is important for later analysis to explore the feature’s data type and convert them to the correct data types\n",
        "*   There are many types in pandas, Objects can be letters or words, Int64 are integers and Floats are real numbers.\n",
        "\n",
        "#### Correcting data types\n",
        "\n",
        "*   To identify data types use datafram.dtypes()\n",
        "*   To convert data types use dataframe.astype() to convert data type\n",
        "*   Using astype(“int”) ex for the price column, you can convert the object column into an integer type variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"price\"] = df[\"price\"].astype(\"int\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Normalization in Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*   Normalization can make some statistical analyses easier down the road\n",
        "#### Methods\n",
        "\n",
        "*   The first method, called “simple feature scaling”, just divides each value by the maximum value for that feature. This makes the new values range between 0 and 1.\n",
        "\n",
        "*   The second method, called “Min-Max”, takes each value, X_old, subtracted from the minimum value of that feature, then divides by the range of that feature.\n",
        "\n",
        "*   The third method is called “z-score” or “standard score”. In this formula, for each value, you subtract the Mu which is the average of the feature, and then divide by the standard deviation (sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Binning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*   Grouping of values into \"bins\"\n",
        "*   Converts numeric into categorical variables\n",
        "*   Group a set of numerical values into a set of \"bins\"\n",
        "*   Binning can improve accuracy of the predictive models\n",
        "*   Sometimes we use data binning to group a set of numerical values into a smaller number of bins to have a better understanding of the data distribution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bins = np.linspace(min(df[\"price\"]), max(df[\"price\"]),4)\n",
        "group_names=[\"Low\",\"Medium\",\"High\"]\n",
        "df[\"price_binned\"]=pd.cut(df[\"price\"],bins,labels=group_names,include_lowest=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*   First we use the numpy function “linspace” to return the array “bins” that contains 4 equally spaced numbers over the specified interval of the price\n",
        "*   We create a list “group_names “ that contains the different bin names\n",
        "*   We use the pandas function ”cut” to segment and sort the data values into bins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Turning categorical variables into quantitative variables"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "assignment01.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
