{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tec03/ParaAssignment01-/blob/main/assignment01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation and Refinement \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tells us how our model preforms in the real world\n",
        "-   In sample evaluation tell us how our model wil fit the data used to train it\n",
        "-   We use the test data to get an idea how our model will perform in the real world.\n",
        "-   When we split a data set, usually the larger portion of data is used for training and a smaller part is used for testing.\n",
        "\n",
        "train_test_split() = When we split a data set, usually the larger portion of data is used for training and a\n",
        "smaller part is used for testing.\n",
        "\n",
        "-   This function randomly splits a dataset into training and testing subsets\n",
        "\n",
        "-   When we split a data set, usually the larger portion of data is used for training and a\n",
        "smaller part is used for testing.\n",
        "\n",
        "-   This function randomly splits a dataset into training and testing subsets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generalization Performance\n",
        "\n",
        "Generalization error is a measure of how well our data does at predicting previously unseen data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Overfitting, Underfitting and Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of model selection is to determine the order of the polynomial to provide the best estimate of the function y x.\n",
        "If we try and fit the function with a linear function, the line is not complex enough to fit the data.\n",
        "\n",
        "As a result, there are many errors, This is called under-fitting, where the model is too simple to fit the data.\n",
        "If we increase the order of the polynomial, the model fits better, but the model is still not flexible enough and exhibits under-fittin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Ridge Regression\n",
        "\n",
        "- Ridge regression controls the magnitude of these polynomial coefficients by introducing\n",
        "the parameter alpha.\n",
        "- Alpha is a parameter we select before fitting or training the model.\n",
        "- Each row in the following table represents an increasing value of alpha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- If alpha is too large, the coefficients will approach zero and under-fit the data.\n",
        "- If alpha is zero, the over-fitting is evident.\n",
        "- For alpha equal to 0.001, the over fitting begins to subside.\n",
        "- For alpha equal to 0.01, the estimated function tracks the actual function\n",
        "- When alpha equals 1, we see the first signs of under-fitting\n",
        "- The estimated function does not have enough flexibility.\n",
        "- At alpha equals to 10, we see extreme under-fitting; it does not even track the two points\n",
        "- In order to select alpha we use cross-validation\n",
        "- To make a prediction using ridge regression, import ridge from sklearn linear models\n",
        "- Create a Ridge object using the constructor\n",
        "- The parameter alpha is one of the arguments of the constructor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grid Search\n",
        "\n",
        "Grid search takes the model or objects you would like to train and different values of the hyperparameters. It then calculates the mean square error or R squared for various hyperparameter values, allowing you to choose the best values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = [{'alpha' [1,10,100,1000]}]\n",
        "\n",
        "RR = Ridge()\n",
        "\n",
        "Grid1 = GridSearchCV(RR,parameters,cv=4)\n",
        "Grid1.fit(x_data[['horsepower','curb-weight','engine-size','highway-mpg']],y_data)\n",
        "\n",
        "Grid1.nest_estimator_\n",
        "\n",
        "scores = Grid1.cv_results\n",
        "\n",
        "scores['mean_test_score']\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "assignment01.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
